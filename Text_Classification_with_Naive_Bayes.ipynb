{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Lab\n",
    "## Text Classification with Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Reading files and storing their contents in 2 string arrays.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data_ml_2020/movies_reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'new_movies_reviews', 'neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we put reviews from negative folder into neg_lst string array and put reviews from positive folder into pos_lst string array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of negative reviews: 1000\n",
      "Num of positive reviews: 1005\n"
     ]
    }
   ],
   "source": [
    "neg_lst = []\n",
    "neg_path = data_dir + \"/neg\"\n",
    "for path in os.listdir(neg_path):\n",
    "    if path.endswith('.txt'):\n",
    "        with open(neg_path + '/' + path) as f:\n",
    "            neg_lst.append(f.read())\n",
    "\n",
    "print(\"Num of negative reviews: {}\".format(len(neg_lst)))\n",
    "\n",
    "pos_lst = []\n",
    "pos_path = data_dir + \"/pos\"\n",
    "for path in os.listdir(pos_path):\n",
    "    if path.endswith('.txt'):\n",
    "        with open(pos_path + '/' + path) as f:\n",
    "            pos_lst.append(f.read())\n",
    "\n",
    "print(\"Num of positive reviews: {}\".format(len(pos_lst)))\n",
    "   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Assigning class labels based on directory and combining small lists into one big list</h3>\n",
    "\n",
    "We assign 1 for negative reviews and 0 for positive reviews. We also combine two lists into one list. At first, there were two lists: pos_lst and neg_lst. So we combine it into 1 big list X. Also, we combine the 1's and 0's together into one list Y. Y contains class label (ie. 1 for negative and 0 for positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_neg = np.ones((len(neg_lst),)) # ones for negative\n",
    "Y = np.concatenate((Y_neg, np.zeros((len(pos_lst),)))) # zeros for positive\n",
    "\n",
    "X = np.concatenate((neg_lst,pos_lst))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Split Data</h3>\n",
    "\n",
    "We then split the big list into training and testing set for both X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split dataset into train and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Transformation</h3>\n",
    "\n",
    "We then apply transformations. After assigning unique numbers to each words in text, we count the occurence of each word. In other words, CountVectorizer transforms a given text into vector on the basis of count of each word in each document. So CountVectorizer creates a matrix where each row represents each document and where each column represents each unique word. The value at a particular cell tells us how many times does this word (represented by column) occurs in this document (represented by rows).\n",
    "\n",
    "Right now, if we weigh these words equally, we would find words like 'they' which occurs almost in every texts as important. So we need to find a way to overcome this problem.\n",
    "\n",
    "We can use TFidfTransformer.\n",
    "We pass the array of counts (matrix) from CountVectorizer to Term Frequency Inverse Document Frequency (TfidfTransformer), which counts the number of times a word appears in a document and we give weights to the word so that word such as \"the\" will be less significant even though it occurs many times in many documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_count = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Training the Model</h3>\n",
    "\n",
    "We will then build a model using training dataset. I use ComplementNB as it works well with text classification and we see that the data is imbalanced because there are 1000 negative reviews and 1005 positive reviews. ComplementNB will give higher accuracy when the dataset is imbalanced compared to MultinominalNB and GaussianNB.\n",
    "\n",
    "ComplementNB is an adaptated form of MultinominalNB. MultinominalNB does not work well on imbalanced datasets, meaning that the number of examples of a class is higher than the number of examples of another class. In this case, we have imbalanced datasets since number of positive reviews > number of negative reviews. Even though the number of positive reviews is not that much greater than the number of negative reviews, I would consider to use Complement NB. So basically, as the difference is not that great, we could still use MultinomialNB.\n",
    "\n",
    "Actually I have tried out both the MultinomialNB and ComplementNB and finds that ComplementNB was able to produce a little bit better accuracy (results are shown below) so I plan to use ComplementNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "\n",
    "#clf = MultinomialNB().fit(X_train_tfidf, Y_train)\n",
    "clf = ComplementNB().fit(X_train_tfidf, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9706982543640897 \n",
      "train accuracy 0.9706982543640897\n"
     ]
    }
   ],
   "source": [
    "# to get accuracy for training set\n",
    "acc_train = clf.score(X_train_tfidf, Y_train)\n",
    "print(\"train accuracy: {} \".format(acc_train))\n",
    "\n",
    "\n",
    "# testing with accuracy_score\n",
    "predicted = clf.predict(X_train_tfidf)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"train accuracy\", accuracy_score(Y_train, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8354114713216958 \n",
      "test accuracy 0.8354114713216958\n"
     ]
    }
   ],
   "source": [
    "# first transform\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# to get accuracy for testing set\n",
    "acc_test = clf.score(X_test_tfidf, Y_test)\n",
    "print(\"test accuracy: {} \".format(acc_test))\n",
    "\n",
    "\n",
    "# testing with accuracy_score\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"test accuracy\", accuracy_score(Y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Note:</h4>\n",
    "I have tried it with both multinomialNB and ComplementNB. As shown below, we see that ComplementNB gives a better accuracy for test set than multinomialNB.\n",
    "\n",
    "with MultinomialNB ->\n",
    "\n",
    "    train accuracy: 0.9675810473815462\n",
    "    \n",
    "    test accuracy: 0.8254364089775561 \n",
    "\n",
    "\n",
    "with ComplementNB ->\n",
    "\n",
    "    train accuracy: 0.9706982543640897 \n",
    "    \n",
    "    test accuracy: 0.8354114713216958 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6. Testing with New Reviews</h3>\n",
    "\n",
    "<p>\n",
    "    I have taken 5 new movie reviews from IMDB and the ones I have taken have ratings up to 10.\n",
    "    So we use them to see how our classifier will perform on this new dataset.\n",
    "    \n",
    "The link for new reviews is \n",
    "<a href=\"https://drive.google.com/drive/folders/1XRjgANGakdyKKMXL9zZFz67mtwIt7lCr?usp=sharing\">here\n",
    "</a>:\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_dir = \"../../data_ml_2020/movies_reviews/new_movies_reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews_lst = []\n",
    "for path in sorted(os.listdir(new_data_dir)):\n",
    "    if path.endswith('.txt'):\n",
    "        with open(new_data_dir + '/' + path) as f:\n",
    "            new_reviews_lst.append(f.read())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "X_new_counts = count_vect.transform(new_reviews_lst)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "print(predicted)\n",
    "\n",
    "# 0's for positive and 1's for negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Note:</h4> \n",
    "<p>\n",
    "    I consider above half (ie. above 5/10) to be positive and the rest to be negative\n",
    "</p>\n",
    "\n",
    "<h4>Result</h4>\n",
    "\n",
    "[0. 0. 0. 1. 0.]\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "    1st file ->\n",
    "\n",
    "    Rating: 7/10\n",
    "    predicted: <b>positive</b> \n",
    "    actual: <b>positive</b>\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    2nd file ->\n",
    "\n",
    "    Rating: 10/10;\n",
    "    predicted: <b>positive</b> \n",
    "    actual: <b>positive</b>\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    3rd file ->\n",
    "\n",
    "    Rating: 3/10;\n",
    "    predicted: <b>positive</b> \n",
    "    actual: <b>negative</b>    ;\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    4th file ->\n",
    "\n",
    "    Rating: 3/10;\n",
    "    predicted: <b>negative</b>  ;\n",
    "    actual: <b>negative</b>\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "    5th file ->\n",
    "\n",
    "    Rating: 8/10;\n",
    "    predicted: <b>positive</b>. ;\n",
    "    actual: <b>positive</b>\n",
    "</li>    \n",
    "\n",
    "</ul>\n",
    "\n",
    "<p>Out of all 5 new reviews, the classifier was able to predict 4 correctly.</p>\n",
    "\n",
    "<p>\n",
    "    The classifier was not able to predict correctly for the 3rd text file. When I look at that review, I see things like \"A 3-star is probably the best rating that I can give here.\" So I think the classifier associates 'best' as positive even though that person only gives 3 out of 10 stars. Then that person explains why 3 star was given. When explaining that, there are some positive words and maybe that's why the classifier thinks it's a positive review whereas it's actually a negative review. That person also states \"IMDB won't allow me to give a ZERO star for the worst movie of all time\".  \n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7. References</h3>\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html#sklearn.naive_bayes.ComplementNB\n",
    "\n",
    "https://heartbeat.fritz.ai/understanding-naive-bayes-its-applications-in-text-classification-part-1-ec9caea4baae\n",
    "\n",
    "https://medium.com/analytics-vidhya/tf-idf-term-frequency-technique-easiest-explanation-for-text-classification-in-nlp-with-code-8ca3912e58c3\n",
    "\n",
    "https://www.geeksforgeeks.org/complement-naive-bayes-cnb-algorithm/\n",
    "\n",
    "For new review 1: https://www.imdb.com/review/rw0893947/?ref_=ur_urv\n",
    "\n",
    "For new review 2: https://www.imdb.com/review/rw2764760/?ref_=tt_urv\n",
    "\n",
    "For new review 3: https://www.imdb.com/review/rw6094710/?ref_=ur_urv\n",
    "\n",
    "For new review 4: https://www.imdb.com/review/rw3315212/?ref_=tt_urv\n",
    "\n",
    "For new review 5: https://www.imdb.com/review/rw2770824/?ref_=tt_urv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
